{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "data = pd.read_csv('MINST_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "\n",
       "[3 rows x 785 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        0\n",
       "2        1\n",
       "3        4\n",
       "4        0\n",
       "        ..\n",
       "41995    0\n",
       "41996    1\n",
       "41997    7\n",
       "41998    6\n",
       "41999    9\n",
       "Name: label, Length: 42000, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.pop(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "X Shape (Cols, Rows) (784, 42000)\n",
      "Y Shape (Cols, Rows) (42000,)\n"
     ]
    }
   ],
   "source": [
    "# Assign X & Y, and divide by 255 to scale to 0-1 and have no overflow error when doing exponential operations.\n",
    "    # Divide by 255 as there are 256 possible pixel values (0->255)\n",
    "\n",
    "# We transpose the data to match the shape the weights matrices will be in:\n",
    "#   Neurons:\n",
    "#   [ neuron 1      weight1, weight2, weight3 ]\n",
    "#   [ neuron 2      weight1, weight2, weight3 ]\n",
    "#   [ neuron 3      weight1, weight2, weight3 ]\n",
    "#   [ neuron 10     weight1, weight2, weight3 ]\n",
    "#\n",
    "#   Pixels:\n",
    "#   [ pixel1        example1, example2, example3 ]\n",
    "#   [ pixel2        example1, example2, example3 ]\n",
    "#   [ pixel3        example1, example2, example3 ]\n",
    "#   ...\n",
    "#   [ pixel748      example1, example2, example3 ]\n",
    "\n",
    "# Data -> [ pix1, pix2, pix3 .....\n",
    "#         [ example1 pixel 1, example1 pixel2, example1 pixel3 ....\n",
    "#         [ example2 pixel 1, example2 pixel2, example2 pixel3 ....\n",
    "X = data.T / 255\n",
    "\n",
    "# Data.T (Transposed, or \"Flipped\") ->  [ pix1 example1 pixel 1, example2 pixel 1, example3 pixel1, .....\n",
    "#                                       [ pix2 example1 pixel 2, example2 pixel 2, example3 pixel2, .....\n",
    "#                                       [ pix3 example1 pixel 3, example2 pixel 3, example3 pixel3, .....\n",
    "\n",
    "# Before transposing, each column to the right is a new pixel of the same example\n",
    "# After transposing, each column to the right is a new example of the same pixel\n",
    "\n",
    "Y = np.array(pd.read_csv('MINST_train.csv').pop(\"label\")) / 255\n",
    "\n",
    "print(\"X Shape (Rows, Cols)\", X.shape)  # 784 pixels of a 28x28 image down the way, and 42000 image examples along to the right\n",
    "print(\"Y Shape (Rows, Cols)\", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A neural net is made up of inputs, weights & biases on each neuron, an activation function for each neuron, & final outputs\n",
    "    # 1. Input features\n",
    "    # 2. Layer(s) of Neurons: Weights, biases, and activation functions\n",
    "    # 3. Output\n",
    "\n",
    "# Training a neural network is done by propagating inputs through the layers of the network, then going backwards to optimise based on an error value.\n",
    "# You do this repeatedly.\n",
    "\n",
    "# Need weights & biases\n",
    "def initialise_neural_net_parameters(n_features, n_neurons=10):\n",
    "    '''\n",
    "    @returns W1, b1, W2, b2\n",
    "    \n",
    "    - W1: Each neuron's weights for every input feature (all input features go to each neuron)\n",
    "    - W2: Each neuron's weights for each of the previous layer's outputs (all inputs from last layer go to each neuron)\n",
    "    - b1: bias for the first layer\n",
    "    - b2: bias for the second layer\n",
    "    '''\n",
    "\n",
    "    W1 = np.random.rand(n_neurons, n_features)  # 10 rows, 784 columns -> weights for all features\n",
    "                                                    # Each row is a neuron, and each neuron has 784 weights\n",
    "                                                    # There are 784 weights per neuron, as each neuron receives input from each pixel in input layer\n",
    "    W2 = np.random.rand(n_neurons, n_neurons)   # 10 rows, 10 columns -> weights for the 10 neurons in 2nd layer\n",
    "                                                    # Each row is a neuron, and each neuron has 10 weights\n",
    "                                                    # There are 10 weights per neuron as each neuron receives input from the 10 neurons in last layer\n",
    "\n",
    "    b1 = np.random.rand(10, 1)\n",
    "    b2 = np.random.rand(10, 1)\n",
    "\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "def ReLU(input):\n",
    "    '''Linear Function which floors the lowest value at 0, else takes the positive value.'''\n",
    "    return np.maximum(0, input)\n",
    "\n",
    "def ReLU_derivative(input):\n",
    "    '''Returns slope of line as 1 if greater than 0, else slope of line as 0 if <= 0'''\n",
    "    return input > 0\n",
    "\n",
    "def softmax(input):\n",
    "    '''Converts a vector of numbers into a vector of probabilities based on the total (if 1,1,1, then probability of each is .33)'''\n",
    "    return np.exp(input) / np.sum(np.exp(input))\n",
    "\n",
    "# Need forward propagation to train\n",
    "def forward_propagation(W1, b1, W2, b2, X):\n",
    "    '''\n",
    "    Calculate output of each layer\n",
    "    @returns layer1WBOut, layer1ActivationOut, layer2WBOut, layer2ActivationOut\n",
    "    '''\n",
    "    \n",
    "    # Output of a layer is ϕ((X * W) + b)\n",
    "        # ϕ is activation function\n",
    "        # X is matrix of inputs (we will multiply each input by weight)\n",
    "        # W is weights (we will multiply each weight by each input)\n",
    "        # b is bias\n",
    "    \n",
    "    # 1st layer uses pixel input with weights & bias\n",
    "    layer1WeightBiasOutput = W1.dot(X) + b1\n",
    "    layer1ActivationOutput = ReLU(layer1WeightBiasOutput)       # functions are what make a NN linear or non-linear\n",
    "\n",
    "    # 2nd layer uses output from layer 1 as input against its weights & bias\n",
    "    layer2WeightBiasOutput = W2.dot(layer1ActivationOutput) + b2\n",
    "    layer2ActivationOutput = softmax(layer2WeightBiasOutput)    # functions are what make a NN linear or non-linear\n",
    "\n",
    "    return layer1WeightBiasOutput, layer1ActivationOutput, layer2WeightBiasOutput, layer2ActivationOutput\n",
    "\n",
    "def backward_propagation(L1WB, L1A, L2WB, L2A, W2, X, Y):\n",
    "    '''\n",
    "    Figures out how much each part of each layer contributed to the error\n",
    "    @returns l1WErr, l1bErr, l2WErr, l2bErr\n",
    "    '''\n",
    "    \n",
    "    # TODO: 1-hot encoding?\n",
    "\n",
    "    # how much did each part of each layer contribute to error?\n",
    "    layer2Error = L2A - Y\n",
    "    layer2WeightError = (1 / Y.size) * layer2Error.dot(L1A.T)\n",
    "    layer2BiasError = (1 / Y.size) * np.average(layer2Error)\n",
    "\n",
    "    layer1Error = W2.T.dot(layer2Error) * ReLU_derivative(L1A)\n",
    "    layer1WeightError = (1 / Y.size) * layer1Error.dot(X.T)\n",
    "    layer1BiasError = (1 / Y.size) * np.average(layer1Error)\n",
    "\n",
    "    return layer1WeightError, layer1BiasError, layer2WeightError, layer2BiasError\n",
    "\n",
    "def update_neural_net_parameters(W1, b1, W2, b2, errW1, errb1, errW2, errb2, alpha):\n",
    "    '''@returns new W1, b1, W2, b2'''\n",
    "    W1 = W1 - alpha * errW1\n",
    "    b1 = b1 - alpha * errb1\n",
    "\n",
    "    W2 = W2 - alpha * errW2\n",
    "    b2 = b2 - alpha * errb2\n",
    "\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(L2A):\n",
    "    # Get indices of largest values\n",
    "    return np.argmax(L2A, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "def gradient_descent(X, Y, iterations, alpha):\n",
    "    W1, b1, W2, b2 = initialise_neural_net_parameters(n_features=X.shape[0])\n",
    "\n",
    "    for i in range(iterations):\n",
    "        layer1WeightBiasOutput, layer1ActivationOutput, layer2WeightBiasOutput, layer2ActivationOutput = forward_propagation(W1, b1, W2, b2, X)\n",
    "        l1WErr, l1bErr, l2WErr, l2bErr = backward_propagation(layer1WeightBiasOutput, layer1ActivationOutput, layer2WeightBiasOutput, layer2ActivationOutput,\n",
    "                                                                W2, X, Y)\n",
    "        W1, b1, W2, b2 = update_neural_net_parameters(W1, b1, W2, b2, l1WErr, l1bErr, l2WErr, l2bErr, alpha)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration:\", i)\n",
    "            predictions = get_predictions(layer2WeightBiasOutput)\n",
    "            print(get_accuracy(predictions, Y))\n",
    "    \n",
    "    return W1, b1, W2, b2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num input features: 784\n",
      "Iteration: 0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\AppData\\Local\\Temp\\ipykernel_11780\\1556481918.py:27: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(input) / np.sum(np.exp(input))\n",
      "C:\\Users\\Ben\\AppData\\Local\\Temp\\ipykernel_11780\\1556481918.py:27: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.exp(input) / np.sum(np.exp(input))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10\n",
      "0.09838095238095237\n",
      "Iteration: 20\n",
      "0.09838095238095237\n",
      "Iteration: 30\n",
      "0.09838095238095237\n",
      "Iteration: 40\n",
      "0.09838095238095237\n",
      "Iteration: 50\n",
      "0.09838095238095237\n",
      "Iteration: 60\n",
      "0.09838095238095237\n",
      "Iteration: 70\n",
      "0.09838095238095237\n",
      "Iteration: 80\n",
      "0.09838095238095237\n",
      "Iteration: 90\n",
      "0.09838095238095237\n",
      "Iteration: 100\n",
      "0.09838095238095237\n",
      "Iteration: 110\n",
      "0.09838095238095237\n",
      "Iteration: 120\n",
      "0.09838095238095237\n",
      "Iteration: 130\n",
      "0.09838095238095237\n",
      "Iteration: 140\n",
      "0.09838095238095237\n",
      "Iteration: 150\n",
      "0.09838095238095237\n",
      "Iteration: 160\n",
      "0.09838095238095237\n",
      "Iteration: 170\n",
      "0.09838095238095237\n",
      "Iteration: 180\n",
      "0.09838095238095237\n",
      "Iteration: 190\n",
      "0.09838095238095237\n",
      "Iteration: 200\n",
      "0.09838095238095237\n",
      "Iteration: 210\n",
      "0.09838095238095237\n",
      "Iteration: 220\n",
      "0.09838095238095237\n",
      "Iteration: 230\n",
      "0.09838095238095237\n",
      "Iteration: 240\n",
      "0.09838095238095237\n",
      "Iteration: 250\n",
      "0.09838095238095237\n",
      "Iteration: 260\n",
      "0.09838095238095237\n",
      "Iteration: 270\n",
      "0.09838095238095237\n",
      "Iteration: 280\n",
      "0.09838095238095237\n",
      "Iteration: 290\n",
      "0.09838095238095237\n",
      "Iteration: 300\n",
      "0.09838095238095237\n",
      "Iteration: 310\n",
      "0.09838095238095237\n",
      "Iteration: 320\n",
      "0.09838095238095237\n",
      "Iteration: 330\n",
      "0.09838095238095237\n",
      "Iteration: 340\n",
      "0.09838095238095237\n",
      "Iteration: 350\n",
      "0.09838095238095237\n",
      "Iteration: 360\n",
      "0.09838095238095237\n",
      "Iteration: 370\n",
      "0.09838095238095237\n",
      "Iteration: 380\n",
      "0.09838095238095237\n",
      "Iteration: 390\n",
      "0.09838095238095237\n",
      "Iteration: 400\n",
      "0.09838095238095237\n",
      "Iteration: 410\n",
      "0.09838095238095237\n",
      "Iteration: 420\n",
      "0.09838095238095237\n",
      "Iteration: 430\n",
      "0.09838095238095237\n",
      "Iteration: 440\n",
      "0.09838095238095237\n",
      "Iteration: 450\n",
      "0.09838095238095237\n",
      "Iteration: 460\n",
      "0.09838095238095237\n",
      "Iteration: 470\n",
      "0.09838095238095237\n",
      "Iteration: 480\n",
      "0.09838095238095237\n",
      "Iteration: 490\n",
      "0.09838095238095237\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(X, Y, iterations=500, alpha=0.10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a4529d362443c2a61b6a121728dcb0b47747083ab16ccf8ac876b4772a1fa39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
